{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from skimage.filters import threshold_sauvola\n",
    "import matplotlib.pyplot as plt\n",
    "from heapq import *\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drushti(img,enhance):\n",
    "    try:\n",
    "        \"\"\"Image read as grayscale, \n",
    "        appling median blur for noise removal,\n",
    "        binarizing image using sauvola thresholding and inverting it\"\"\"\n",
    "        filename = img\n",
    "        img = cv2.imread(img,0)\n",
    "        img = cv2.medianBlur(img, 3)\n",
    "        window_size=15\n",
    "        thresh_sauvola = threshold_sauvola(img, window_size=window_size)\n",
    "        binary_sauvola = img > thresh_sauvola\n",
    "        im = (binary_sauvola*255).astype(np.uint8)\n",
    "        im = im.copy()\n",
    "        im = abs(255-im)\n",
    "        im = im/255\n",
    "        #plt.imshow(im,cmap=\"gray\")\n",
    "        if enhance==True:\n",
    "            \"\"\"Applying morphological operations \"\"\"\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            im = cv2.erode(im, kernel, iterations=2)\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            im = cv2.dilate(im, kernel, iterations=3)\n",
    "        horizontal = np.sum(im, axis=1) \n",
    "        peaks_index = find_peak_regions(horizontal)\n",
    "        try:\n",
    "            clusters = get_clusters(peaks_index)\n",
    "            for cluster_of_interest in clusters:\n",
    "                nmap = im[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:]\n",
    "                blocks = get_block_regions(nmap)\n",
    "                blocks_cluster_groups=get_clusters(blocks)\n",
    "\n",
    "                for index, blocks in enumerate(blocks_cluster_groups):           \n",
    "                    window = nmap[:, blocks[0]: blocks[1]+10]\n",
    "                    im[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:][:, blocks[0]:blocks[1]+10][int(window.shape[0]/2),:] *= 0\n",
    "        except Exception:\n",
    "            pass\n",
    "        line_segments = []\n",
    "        lens = 0\n",
    "        for l in clusters:\n",
    "            if l!=None:lens+=len(l)\n",
    "        avglen = int(lens/len(clusters))\n",
    "        for i, cluster_of_interest in enumerate(clusters):\n",
    "\n",
    "            if len(cluster_of_interest) >avglen:  ##WHY 10? minimum lettersize\n",
    "                nmap = im[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:]\n",
    "                path = np.array(astar(nmap, (int(nmap.shape[0]/2), 0), (int(nmap.shape[0]/2),nmap.shape[1]-1)))\n",
    "                #path = np.array(astar(nmap, (0, 0), (0,nmap.shape[1]-1)))\n",
    "                offset_from_top = cluster_of_interest[0]\n",
    "                if path.shape[0]>1:\n",
    "                    path[:,0] += offset_from_top\n",
    "                    line_segments.append(path)\n",
    "        img =cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "        for path in line_segments:\n",
    "            for index, item in enumerate(path): \n",
    "                if index == len(path) -1:break\n",
    "                cv2.line(img, (item[1],item[0]),(path[index + 1][1],path[index + 1][0]), [0, 255, 0], 2)\n",
    "        return img\n",
    "    except Exception as ex:\n",
    "        print(\"Exception Occured at \",ex)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(peaks_index):\n",
    "    clusters = []\n",
    "    minclus = []\n",
    "    for i in range(len(peaks_index)):\n",
    "        if i+1==len(peaks_index):\n",
    "            if len(minclus):\n",
    "                if peaks_index[i]-minclus[-1] <2:\n",
    "                    minclus.append(peaks_index[i])\n",
    "                    clusters.append(minclus)\n",
    "                else:\n",
    "                    clusters.append(minclus)\n",
    "                    minclus = []\n",
    "                    clusters.append(minclus.append(peaks_index[i]))\n",
    "            else:\n",
    "                clusters.append(minclus.append(peaks_index[i]))\n",
    "            break\n",
    "        if (peaks_index[i+1] - peaks_index[i])<2:\n",
    "            minclus.append(peaks_index[i])\n",
    "        else:\n",
    "            minclus.append(peaks_index[i])\n",
    "            clusters.append(minclus)\n",
    "            minclus=[]\n",
    "    clusters = [x for x in clusters if x is not None]\n",
    "    return clusters\n",
    "def find_peak_regions(hpp, divider=2):\n",
    "    threshold =(np.max(hpp)-np.min(hpp))/divider\n",
    "    peaks = []\n",
    "    peaks_index = []\n",
    "    print(threshold)\n",
    "    for i, hppv in enumerate(hpp):\n",
    "        if hppv < threshold:\n",
    "            peaks.append(i)\n",
    "    return peaks\n",
    "\n",
    "def heuristic(a, b):\n",
    "    return (b[0] - a[0]) ** 2 + (b[1] - a[1]) ** 2\n",
    "\n",
    "#a star path planning algorithm\n",
    "def astar(array, start, goal):\n",
    "\n",
    "    neighbors = [(0,1),(0,-1),(1,0),(-1,0),(1,1),(1,-1),(-1,1),(-1,-1)]\n",
    "    close_set = set()\n",
    "    came_from = {}\n",
    "    gscore = {start:0}\n",
    "    fscore = {start:heuristic(start, goal)}\n",
    "    oheap = []\n",
    "\n",
    "    heappush(oheap, (fscore[start], start))\n",
    "    \n",
    "    while oheap:\n",
    "\n",
    "        current = heappop(oheap)[1]\n",
    "\n",
    "        if current == goal:\n",
    "            data = []\n",
    "            while current in came_from:\n",
    "                data.append(current)\n",
    "                current = came_from[current]\n",
    "            return data\n",
    "\n",
    "        close_set.add(current)\n",
    "        for i, j in neighbors:\n",
    "            neighbor = current[0] + i, current[1] + j            \n",
    "            tentative_g_score = gscore[current] + heuristic(current, neighbor)\n",
    "            if 0 <= neighbor[0] < array.shape[0]:\n",
    "                if 0 <= neighbor[1] < array.shape[1]:                \n",
    "                    if array[neighbor[0]][neighbor[1]] == 1:\n",
    "                        continue\n",
    "                else:\n",
    "                    # array bound y walls\n",
    "                    continue\n",
    "            else:\n",
    "                # array bound x walls\n",
    "                continue\n",
    "                \n",
    "            if neighbor in close_set and tentative_g_score >= gscore.get(neighbor, 0):\n",
    "                continue\n",
    "                \n",
    "            if  tentative_g_score < gscore.get(neighbor, 0) or neighbor not in [i[1]for i in oheap]:\n",
    "                came_from[neighbor] = current\n",
    "                gscore[neighbor] = tentative_g_score\n",
    "                fscore[neighbor] = tentative_g_score + heuristic(neighbor, goal)\n",
    "                heappush(oheap, (fscore[neighbor], neighbor))\n",
    "                \n",
    "    return []\n",
    "def path_exists(window):\n",
    "    #very basic check first then proceed to A* check\n",
    "    if 0 in np.sum(window, axis=1):\n",
    "        return True\n",
    "    \n",
    "    padded_window = np.zeros((window.shape[0],1))\n",
    "    chunk = np.hstack((padded_window, np.hstack((window,padded_window)) ) )\n",
    "    path = np.array(astar(chunk, (int(chunk.shape[0]/2), 0), (int(chunk.shape[0]/2), chunk.shape[1])))\n",
    "    if len(path) > 0:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "def get_block_regions(nmap):\n",
    "    blocks = []\n",
    "    needtobreak = False\n",
    "    \n",
    "    for col in range(nmap.shape[1]):\n",
    "        start = col\n",
    "        end = col+20\n",
    "        if end > nmap.shape[1]-1:\n",
    "            end = nmap.shape[1]-1\n",
    "            needtobreak = True\n",
    "\n",
    "        if path_exists(nmap[:, start:end]) == False:\n",
    "            blocks.append(col)\n",
    "\n",
    "        if needtobreak == True:\n",
    "            break\n",
    "            \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data_totry/PGY_7.jpg\"\n",
    "enhance = True\n",
    "img = drushti(filename,enhance)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "filename = os.path.splitext(filename)[0]+\"_output.png\"\n",
    "cv2.imwrite(filename,img)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
